\section{Curva A}

En este punto se presenta una nueva herramienta gráfica que permite la evaluación de un modelo predictivo en base al error que se comente en la predicción. Este nuevo método surge de la necesidad de obtener una forma de representación gráfica que se pueda aplicar tanto a modelos de clasificación binaria como a modelos de clasificación multi etiqueta. La representación gráfica del error se obtiene a partir la fórmula de verificación propuesta por Brier en el artículo \textit{Verification of Forecasts Expressed in Terms of Probability} \cite{brie_1950}.

\bigbreak

La fórmula de verificación de Brier se define como el sumatorio del error cuadrático medio entre la clase y las diferentes probabilidades que asigna el modelo a cada etiqueta. La fórmula de verificación constituye un punto de partida ideal ya que se define teniendo en cuenta su aplicación a modelos de clasificación con más de dos clases. La representación del error que se hace en la fórmula de verificación también es independiente del balance entre el número de instancias de cada clase, esto supone un punto positivo a tener en cuenta.

\bigbreak

\begin{equation}
    P = \frac{1}{n}\sum_{j=1}^{r}\sum_{i=1}^{n}{(f_{ij}-E_{ij})^{2}}
    \label{eq:BrierScore}
\end{equation}

\bigbreak


En la ecuación \ref{eq:BrierScore} se representa la definición original de la fórmula de verificación. El parámetro $E_{ij}$ indica si la clase del registro $i$ coincide con la etiqueta $j$. El indicador $f_{ij}$ representa la probabilidad que se le asigna al registro $i$ de pertenecer a la clase $j$.

\bigbreak

El resultado que se obtiene al aplicar la fórmula de verificación se encuentra en el intervalo de cero a dos. En el caso de un modelo de clasificación binario en el que se predicen positivos los registros negativos y negativos los registros positivos, el resultado obtenido es de dos unidades. Por el contrario, si se clasifican correctamente todos los registros, el resultado obtenido es de cero.

\bigbreak

Para facilitar la interpretación de la curva A, se propone una modificación de la fórmula de verificación. El objetivo de redefinir la fórmula es obtener una gráfica que tenga una interpretación similar a la curva ROC. En la ecuación \ref{eq:A} aparece representada la fórmula que se utilizara en el cálculo de la curva A. El resultado que se obtiene de la nueva fórmula se encuentra en el intervalo de cero a uno, los valores próximos a uno indican tasas de error más bajas, mientras que los valores próximos a cero indican tasas de error más altas. Hay que tener en cuenta que la aplicación del método ya no se hace sobre todas las instancias del modelo, sino que se aplica de forma individual a cada registro.

\bigbreak

\begin{equation}
    A = 1-\frac{\sum_{i=1}^{r}{(f_{i}-E_{i})^{2}}}{2}
    \label{eq:A}
\end{equation}

\bigbreak



La representación de la curva A se hace a partir de los valores obtenidos al aplicar la formula \ref{eq:A} a cada uno de los registros del conjunto de entrenamiento. Es importante aclarar que antes de generar la curva el conjunto de datos con los resultados tiene que estar ordenado. Para representar los puntos en la gráfica, a cada resultado se le asigna un valor equidistante entre cero y uno que permite representar los resultados obtenidos en base al orden establecido. En el eje de ordenadas se representan los resultados obtenidos al aplicar la formula, en el eje de abscisas se representan los puntos de apoyo calculados para cada resultado.

\bigbreak

La interpretación que se hace de la gráfica es muy similar a la que se hace en la curva ROC, cuanto más se aproxime la gráfica al punto $(0, 1)$ mejores tasas de acierto tendrá el modelo. Las curvas que se encuentren por debajo de la diagonal secundaria indican que el modelo tiene tasas de acierto inferior a las de un modelo de clasificación aleatoria. En la Figura \ref{fig:1} se puede ver en azul la curva que presenta un modelo con una clasificación perfecta, por otro lado, la curva naranja es la curva que presenta un modelo de clasificación aleatoria.

\bigbreak

\begin{figure}[htp]
    \centering
    \includegraphics[scale=0.45]{interpretación_curva_a.PNG}
    \caption{Gráfica para la interpretación de la curva A.}
    \label{fig:1}
\end{figure}

\bigbreak

En la Figura \ref{fig:2} se muestra una comparativa entre las curvas A y ROC obtenidas para un modelo de clasificación con cuatro etiquetas. En el primer gráfico se puede observar que la aplicación de la curva ROC en un modelo con cuatro etiquetas implica un aumento de la complejidad en la interpretación de los resultados. El uso de curvas ROC en modelos de clasificación multi etiqueta, también afecta a las conclusiones que se pueden extraer de la calidad general del modelo, esta incapacidad de sacar conclusiones afecta negativamente al proceso de toma de decisiones. La curva A supone una excelente alternativa, el gráfico que se genera para un modelo de clasificación con cuatro etiquetas está compuesto tan solo por una curva, esto supone una mejora en la claridad y en la interpretación de la información. 

\bigbreak

\begin{figure}[htp]
    \centering
     \subfloat[Curva ROC]{
       \includegraphics[width=0.45\textwidth]{brain_gse15824_ROC.PNG}}
     \subfloat[Curva A]{
       \includegraphics[width=0.45\textwidth]{brain_gse15824_A_CURVE.PNG}}
    \caption{Curvas obtenidas para el fichero brain\_gse15824.csv.}
    \label{fig:2}
\end{figure}

\bigbreak

Hay situaciones en las que no es posible establecer una comparativa exclusivamente gráfica entre varias representaciones de la curva A. La definición que se hace de la curva implica que el área bajo la curva aumenta a medida que la curva se aproxima al punto (0, 1), es decir, cuanto mayor es el valor del área bajo la curva mejores tasas de acierto obtiene el modelo. El área bajo la curva, también se puede considerar como un indicador de la calidad general del modelo. El resultado que ofrece, se encuentra en el intervalo de cero a uno, los valores cercanos a uno indican que el modelo tiene buenas tasas de acierto en la predicción, mientras que los valores próximos a cero indican la presencia de un modelo con una muy baja capacidad predictiva. Por último, cabe destacar el grado de similitud entre la exactitud y el área bajo la curva A, esta relección será objeto de estudio en la parte experimental.

\bigbreak

El Algoritmo \ref{al:a_curve} presenta una implementación para obtener los puntos que definen la curva-A, la función recibe como entrada dos matrices de datos. En la variable L se define una matriz de dimensión $NxM$ donde $N$ es el número de registros y $M$ es el número de etiquetas, en cada celda de la matriz se indica con los valores cero o uno si el registro $i$ tiene asignada la etiqueta $j$. En la variable P se define una matriz de dimensión $NxM$ donde $N$ es el número de registros y $M$ es el número de etiquetas, en cada celda se almacena la probabilidad que asigna el modelo al registro $i$ de pertenecer a la clase $j$. La complejidad del algoritmo es $\mathcal{O}(n \cdot m + n \log(n))$, sin embargo, el número de etiquetas se puede considerar como un valor constante dentro del problema al aplicar esta simplificación la complejidad pasa a ser igual al coste de ordenación $\mathcal{O}(n \log(n))$. El algoritmo recorre los distintos registros (bucle, línea 4), por cada registro aplica la formula \ref{eq:A}. Para la aplicación de la formula se calcula en primer lugar el valor del sumatorio, una vez calculado se divide el resultado entre dos y se le resta a la unidad. Por ultimo, se ordena el conjunto de datos R siguiendo un orden ascendente (función, línea 11).

\bigbreak


\bigbreak

\begin{algorithm}
    \caption{Curva-A}
        \begin{algorithmic}[1]
            \State $L$
            \State $P$
            \State $R = [\phantom{.}]$

            \For{$i = 1$ to $|L|$}
                \State $R[i] = 0$
                \For{$j = 1$ to $|L[i]|$}
                    \State $R[i]$ += pow $(L[i][j]-P[i][j], 2)$
                \EndFor
                \State $R[i] = 1 - (R[i]/2)$
            \EndFor
            \State  sort $(R, asc)$
    \end{algorithmic}
    \label{al:a_curve}
\end{algorithm}

\bigbreak

\begin{table}[htp]
    \small
    \centering
    \begin{tabular}{c c c c c c c c c}
        ID  & \hspace{10pt}$L_{0}$  & \hspace{10pt}$L_{1}$  & \hspace{10pt}$L_{2}$  & \hspace{10pt}$P_{0}$ & \hspace{10pt}$P_{1}$ & \hspace{10pt}$P_{2}$  & \hspace{10pt}$E_{R}$ & \hspace{10pt}$1-E_{R}/2$ \\\hline
        $1$ & \hspace{10pt}$1$ & \hspace{10pt}$0$ & \hspace{10pt}$0$ & \hspace{10pt}$0.5$ & \hspace{10pt}$0.2$ & \hspace{10pt}$0$ & \hspace{10pt}$0.29$ & \hspace{10pt}$0.855$           \\\hline
        $2$ & \hspace{10pt}$0$      & \hspace{10pt}$1$ & \hspace{10pt}$0$   & \hspace{10pt}$0.1$    & \hspace{10pt}$0.8$ & \hspace{10pt}$0.1$ & \hspace{10pt}$0.06$ & \hspace{10pt}$0.97$     \\\hline
        $3$ & \hspace{10pt}$1$      & \hspace{10pt}$0$ & \hspace{10pt}$0$   & \hspace{10pt}$1$    & \hspace{10pt}$0$ & \hspace{10pt}$0$ & \hspace{10pt}$0$  & \hspace{10pt}$1$   \\\hline
        $4$ & \hspace{10pt}$0$      & \hspace{10pt}$0$  & \hspace{10pt}$1$  & \hspace{10pt}$0$    & \hspace{10pt}$0.3$ & \hspace{10pt}$0.7$ & \hspace{10pt}$0.18$  & \hspace{10pt}$0.91$    \\\hline
        $5$ & \hspace{10pt}$0$      & \hspace{10pt}$1$ & \hspace{10pt}$0$   & \hspace{10pt}$1$    & \hspace{10pt}$0$ & \hspace{10pt}$0$ & \hspace{10pt}$2$  & \hspace{10pt}$0$    \\\hline
        $6$ & \hspace{10pt}$0$      & \hspace{10pt}$0$  & \hspace{10pt}$1$  & \hspace{10pt}$0$    & \hspace{10pt}$0$ & \hspace{10pt}$1$ & \hspace{10pt}$0$ & \hspace{10pt}$1$    \\\hline
    \end{tabular}
    \caption{Ejemplo propuesto para el calculo de los puntos que representan la curva-A.}
    \label{tab:5}
\end{table}

\clearpage